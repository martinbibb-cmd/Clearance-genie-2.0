<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Clearance Genie AI - Intelligent Clearance Checker</title>

    <!-- OpenCV.js for perspective correction -->
    <script async src="https://docs.opencv.org/4.5.2/opencv.js" onload="onOpenCvReady()"></script>

    <!-- Model Store for boiler, radiator, and cylinder data -->
    <script src="js/modelStore.js"></script>

    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            text-align: center;
            color: white;
            margin-bottom: 30px;
        }

        .header h1 {
            font-size: 32px;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .header .subtitle {
            font-size: 16px;
            opacity: 0.9;
        }

        .card {
            background: white;
            border-radius: 12px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            margin-bottom: 20px;
        }

        .hidden {
            display: none !important;
        }

        /* Equipment Type Selection */
        .equipment-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .equipment-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 40px 20px;
            text-align: center;
            color: white;
            cursor: pointer;
            transition: transform 0.3s, box-shadow 0.3s;
            border: 3px solid transparent;
            touch-action: manipulation;
            -webkit-tap-highlight-color: transparent;
            user-select: none;
        }

        .equipment-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 25px rgba(102, 126, 234, 0.4);
        }

        .equipment-card:active {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.3);
        }

        .equipment-card.selected {
            border-color: #ffd700;
            box-shadow: 0 0 20px rgba(255, 215, 0, 0.5);
        }

        .equipment-card .icon {
            font-size: 60px;
            margin-bottom: 15px;
            pointer-events: none;
        }

        .equipment-card .label {
            font-size: 20px;
            font-weight: 600;
            pointer-events: none;
        }

        .equipment-card .description {
            font-size: 13px;
            margin-top: 10px;
            opacity: 0.9;
            pointer-events: none;
        }

        /* Photo Upload */
        .upload-area {
            border: 3px dashed #667eea;
            border-radius: 12px;
            padding: 40px;
            text-align: center;
            cursor: pointer;
            transition: all 0.3s;
            margin: 20px 0;
        }

        .upload-area:hover {
            background: #f8f9ff;
            border-color: #764ba2;
        }

        .upload-area .icon {
            font-size: 50px;
            margin-bottom: 15px;
        }

        input[type="file"] {
            display: none;
        }

        /* Canvas */
        .canvas-container {
            position: relative;
            margin: 20px 0;
            border-radius: 12px;
            overflow: hidden;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }

        canvas {
            display: block;
            max-width: 100%;
            height: auto;
            cursor: crosshair;
        }

        /* Buttons */
        .btn {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            padding: 15px 30px;
            border-radius: 8px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            width: 100%;
            margin: 10px 0;
            transition: all 0.3s;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
        }

        .btn:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
        }

        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .btn-secondary {
            background: linear-gradient(135deg, #95a5a6 0%, #7f8c8d 100%);
        }

        .btn-success {
            background: linear-gradient(135deg, #2ecc71 0%, #27ae60 100%);
        }

        .btn-small {
            width: auto;
            padding: 10px 20px;
            font-size: 14px;
        }

        /* Instructions */
        .instructions {
            background: #e8f4f8;
            border-left: 4px solid #667eea;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            line-height: 1.6;
        }

        .instructions strong {
            color: #667eea;
        }

        /* Loading Spinner */
        .loading {
            text-align: center;
            padding: 40px;
        }

        .spinner {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #667eea;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            animation: spin 1s linear infinite;
            margin: 0 auto 20px;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        /* Detected Objects List */
        .objects-list {
            margin: 20px 0;
        }

        .object-item {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 0;
            display: flex;
            justify-content: space-between;
            align-items: center;
            border-left: 4px solid #667eea;
        }

        .object-item .info {
            flex: 1;
        }

        .object-item .name {
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 5px;
        }

        .object-item .clearance {
            font-size: 13px;
            color: #7f8c8d;
        }

        .object-item .toggle {
            margin-left: 10px;
        }

        /* Legend */
        .legend {
            display: flex;
            justify-content: space-around;
            flex-wrap: wrap;
            margin: 20px 0;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 8px;
        }

        .legend-item {
            display: flex;
            align-items: center;
            margin: 5px 10px;
        }

        .legend-color {
            width: 30px;
            height: 30px;
            border-radius: 6px;
            margin-right: 10px;
            border: 2px solid #333;
        }

        /* Result */
        .result {
            padding: 30px;
            border-radius: 12px;
            text-align: center;
            font-size: 24px;
            font-weight: 600;
            margin: 20px 0;
        }

        .result.compliant {
            background: linear-gradient(135deg, #2ecc71 0%, #27ae60 100%);
            color: white;
        }

        .result.non-compliant {
            background: linear-gradient(135deg, #e74c3c 0%, #c0392b 100%);
            color: white;
        }

        .result .icon {
            font-size: 60px;
            margin-bottom: 15px;
        }

        .violations {
            background: white;
            color: #c0392b;
            padding: 15px;
            border-radius: 8px;
            margin-top: 15px;
            text-align: left;
            font-size: 14px;
        }

        .violations li {
            margin: 8px 0;
        }

        /* Draggable Equipment */
        .draggable-equipment {
            position: absolute;
            width: 60px;
            height: 60px;
            background: rgba(255, 255, 255, 0.9);
            border: 3px solid #667eea;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 30px;
            cursor: move;
            box-shadow: 0 4px 15px rgba(0,0,0,0.3);
            z-index: 1000;
        }

        /* Model Selection Styles */
        #modelSelect optgroup {
            font-weight: bold;
            font-style: normal;
            background: #f8f9fa;
            padding: 8px;
        }

        #modelSelect option {
            font-weight: normal;
            padding: 8px 12px;
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 24px;
            }

            .equipment-grid {
                grid-template-columns: 1fr;
            }

            .card {
                padding: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üî• Clearance Genie AI</h1>
            <div class="subtitle">Intelligent Clearance Checking with AI Object Detection</div>
        </div>

        <!-- Step 1: Equipment Type Selection -->
        <div class="card" id="step1">
            <h2>Step 1: Select Equipment Type</h2>
            <div class="instructions">
                <strong>Choose what you're checking:</strong> Select the equipment type to analyze clearance requirements.
            </div>
            <div class="equipment-grid">
                <div class="equipment-card" data-type="flue" onclick="selectEquipment('flue')">
                    <div class="icon">üå¨Ô∏è</div>
                    <div class="label">Flue Terminal</div>
                    <div class="description">External clearances to windows, vents, doors</div>
                </div>
                <div class="equipment-card" data-type="boiler" onclick="selectEquipment('boiler')">
                    <div class="icon">üî•</div>
                    <div class="label">Boiler</div>
                    <div class="description">Service clearances to walls, cupboards</div>
                </div>
                <div class="equipment-card" data-type="radiator" onclick="selectEquipment('radiator')">
                    <div class="icon">‚ô®Ô∏è</div>
                    <div class="label">Radiator</div>
                    <div class="description">Clearances to windows, curtains, furniture</div>
                </div>
                <div class="equipment-card" data-type="cylinder" onclick="selectEquipment('cylinder')">
                    <div class="icon">üõ¢Ô∏è</div>
                    <div class="label">Cylinder</div>
                    <div class="description">Service access to doors, shelves, valves</div>
                </div>
            </div>
            <button class="btn" id="continueToPhoto" disabled onclick="goToModelSelection()">Continue to Model Selection</button>
        </div>

        <!-- Step 1b: Model Selection (for boiler, radiator, cylinder) -->
        <div class="card hidden" id="step1b">
            <h2>Step 1b: Select Specific Model</h2>
            <div class="instructions">
                <strong>Choose your equipment model:</strong> Select the specific model to use accurate dimensions and clearances.
            </div>
            <div id="modelSelectionContainer">
                <!-- Will be populated dynamically -->
            </div>
            <div id="selectedModelInfo" style="display: none; background: #d4edda; padding: 15px; border-radius: 8px; margin: 15px 0;">
                <strong>Selected Model:</strong>
                <div id="selectedModelDetails" style="margin-top: 10px;"></div>
            </div>
            <button class="btn" id="continueToCalibration" disabled onclick="goToStep(2)">Continue to Calibration</button>
            <button class="btn btn-secondary" onclick="goToStep(1)">Back to Equipment Selection</button>
        </div>

        <!-- Step 2: Two-Stage Calibration Instructions -->
        <div class="card hidden" id="step2">
            <h2>Step 2: Two-Stage Calibration</h2>
            <div class="instructions">
                <strong>üìê Two-Stage Calibration Process:</strong><br><br>
                This method ensures accurate measurements:<br><br>
                <strong>Stage 1: Close Detection</strong><br>
                Get close to the blue card so it fills most of the frame. This gives the most accurate calibration.<br><br>
                <strong>Stage 2: Wall Capture</strong><br>
                Pull back while keeping the card visible to capture the wall area you need to measure.
            </div>
            <div style="background: #e8f4f8; padding: 15px; border-radius: 8px; margin: 15px 0;">
                <strong style="color: #667eea;">üí° Why Two Stages?</strong><br>
                <ul style="margin-left: 20px; margin-top: 10px; line-height: 1.6;">
                    <li>Calibration only needs the scale reference (blue card)</li>
                    <li>Once locked, you can pull back to see the wall</li>
                    <li>The card just needs to stay on the same wall plane</li>
                    <li>This is how professionals do physical-scale measurement</li>
                </ul>
            </div>
            <div style="margin: 15px 0;">
                <label for="aiModelSelect" style="font-weight: 600; display: block; margin-bottom: 8px;">
                    ü§ñ Select AI Detection Model:
                </label>
                <select id="aiModelSelect" style="width: 100%; padding: 10px; border-radius: 6px; border: 2px solid #667eea; font-size: 15px;">
                    <option value="openai">OpenAI GPT-4 Vision (Default - Best Overall)</option>
                    <option value="together">Together AI - Llama Vision Free (Experimental)</option>
                    <option value="claude">Anthropic Claude 3.5 Sonnet (High Accuracy)</option>
                </select>
                <div id="modelFeedback" style="margin-top: 8px; font-size: 13px; color: #667eea;"></div>
            </div>
            <button class="btn" onclick="goToStage1Calibration()">Begin Stage 1: Close Calibration</button>
            <button class="btn btn-secondary" onclick="goToStep(1)">Back to Equipment Selection</button>
        </div>

        <!-- Step 2a: Stage 1 - Close Calibration -->
        <div class="card hidden" id="step2a">
            <h2>Stage 1: Close Calibration üìè</h2>
            <div class="instructions">
                <strong>üéØ Get Close to the Blue Card:</strong><br><br>
                Hold your blue card (with black X) flat against the wall and position your camera so the card fills most of the frame. This gives the most accurate calibration.
            </div>
            <div style="background: #fff3cd; padding: 15px; border-radius: 8px; margin: 15px 0; border-left: 4px solid #ffc107;">
                <strong>‚ö° Tips for Best Results:</strong>
                <ul style="margin-left: 20px; margin-top: 10px; line-height: 1.8;">
                    <li>Hold card flat against the wall (not tilted)</li>
                    <li>Fill 40-60% of frame with the blue card</li>
                    <li>Ensure good lighting on the card</li>
                    <li>Keep camera parallel to wall</li>
                </ul>
            </div>
            <div class="upload-area" onclick="document.getElementById('stage1CameraInput').click()">
                <div class="icon">üì∏</div>
                <div><strong>Take Close-Up Photo</strong></div>
                <div style="font-size: 14px; margin-top: 10px; color: #7f8c8d;">Position camera close to blue card</div>
            </div>
            <input type="file" id="stage1CameraInput" accept="image/*" capture="environment">
            <div class="upload-area" onclick="document.getElementById('stage1UploadInput').click()">
                <div class="icon">üìÅ</div>
                <div><strong>Upload Existing Photo</strong></div>
                <div style="font-size: 14px; margin-top: 10px; color: #7f8c8d;">Select from device storage</div>
            </div>
            <input type="file" id="stage1UploadInput" accept="image/*">
            <button class="btn btn-secondary" onclick="goToStep(2)">Back to Instructions</button>
        </div>

        <!-- Step 2b: Stage 1 Processing -->
        <div class="card hidden" id="step2b">
            <h2>Stage 1: Processing Calibration</h2>
            <div class="loading">
                <div class="spinner"></div>
                <div id="stage1ProcessingMessage">Detecting blue card and establishing calibration...</div>
            </div>
        </div>

        <!-- Step 2c: Stage 1 Success -->
        <div class="card hidden" id="step2c">
            <h2>Stage 1: Calibration Locked ‚úÖ</h2>
            <div style="background: #d4edda; border: 3px solid #28a745; padding: 25px; border-radius: 12px; margin: 20px 0; text-align: center;">
                <div style="font-size: 60px; margin-bottom: 15px;">üéØ</div>
                <div style="font-size: 24px; font-weight: 600; color: #155724; margin-bottom: 10px;">
                    Calibration Locked!
                </div>
                <div id="calibrationLockedInfo" style="font-size: 16px; color: #155724; line-height: 1.6;">
                    <!-- Will be filled with calibration details -->
                </div>
            </div>
            <div class="instructions">
                <strong>‚úì Stage 1 Complete!</strong><br><br>
                Your calibration is now locked. The camera knows exactly how many pixels = 1mm.<br><br>
                <strong>Next: Pull back for wall capture</strong><br>
                You can now pull back to capture more of the wall, as long as you keep the blue card visible in the frame.
            </div>
            <div class="canvas-container">
                <canvas id="stage1Canvas"></canvas>
            </div>
            <button class="btn btn-success" onclick="goToStage2Capture()">Continue to Stage 2: Wall Capture</button>
            <button class="btn btn-secondary" onclick="retryStage1()">üîÑ Retry Stage 1</button>
        </div>

        <!-- Step 2d: Stage 2 - Wall Capture -->
        <div class="card hidden" id="step2d">
            <h2>Stage 2: Wall Capture üì∏</h2>
            <div style="background: #d4edda; padding: 15px; border-radius: 8px; margin: 15px 0; border-left: 4px solid #28a745;">
                <strong>‚úì Calibration Locked:</strong> <span id="lockedCalibrationDisplay"><!-- Will show locked value --></span>
            </div>
            <div class="instructions">
                <strong>üì∏ Pull Back to Capture Wall Area:</strong><br><br>
                Now that calibration is locked, pull your camera back to capture the wall area you need to measure.<br><br>
                <strong>Important:</strong> Keep the blue card visible in the frame on the same wall plane.
            </div>
            <div style="background: #e8f4f8; padding: 15px; border-radius: 8px; margin: 15px 0;">
                <strong>üí° For Best Results:</strong>
                <ul style="margin-left: 20px; margin-top: 10px; line-height: 1.8;">
                    <li>Keep the blue card visible (can be small in frame)</li>
                    <li>Capture the wall area with windows, vents, or other objects</li>
                    <li>Keep camera roughly parallel to wall</li>
                    <li>The card must stay on the same wall plane</li>
                </ul>
            </div>
            <div class="upload-area" onclick="document.getElementById('stage2CameraInput').click()">
                <div class="icon">üì∏</div>
                <div><strong>Take Wide Photo</strong></div>
                <div style="font-size: 14px; margin-top: 10px; color: #7f8c8d;">Pull back to capture wall area (keep card visible)</div>
            </div>
            <input type="file" id="stage2CameraInput" accept="image/*" capture="environment">
            <div class="upload-area" onclick="document.getElementById('stage2UploadInput').click()">
                <div class="icon">üìÅ</div>
                <div><strong>Upload Existing Photo</strong></div>
                <div style="font-size: 14px; margin-top: 10px; color: #7f8c8d;">Select from device storage</div>
            </div>
            <input type="file" id="stage2UploadInput" accept="image/*">
            <button class="btn btn-secondary" onclick="goToStep('2c')">Back to Stage 1 Results</button>
        </div>

        <!-- Step 2.5: Perspective Correction -->
        <div class="card hidden" id="step2_5">
            <h2>Step 2.5: Perspective Correction</h2>
            <div class="instructions">
                <strong>üìê Correct Camera Angle:</strong> Mark 4 corners of a rectangle to fix perspective distortion.
                <br><br>
                <strong>Choose one:</strong>
                <ul style="margin-left: 20px; margin-top: 10px;">
                    <li>üÉè <strong>Calibration card</strong> (if visible)</li>
                    <li>ü™ü <strong>Window frame</strong></li>
                    <li>üß± <strong>Brick</strong> (try to find one that's rectangular and flat to camera)</li>
                    <li>üì¶ <strong>Any rectangular object</strong></li>
                </ul>
                <br>
                <strong style="color: #667eea;">Click/tap the 4 corners in clockwise order</strong> starting from top-left.
            </div>
            <div id="perspectiveStatus" style="background: #e8f4f8; padding: 15px; border-radius: 8px; margin: 15px 0; font-size: 14px;">
                <strong>Corners marked:</strong> <span id="cornersCount">0 / 4</span>
                <div id="cornersList" style="margin-top: 10px; font-size: 13px;"></div>
            </div>
            <div class="canvas-container" style="cursor: crosshair;">
                <canvas id="perspectiveCanvas"></canvas>
            </div>
            <div style="margin-top: 15px;">
                <button class="btn btn-secondary" onclick="resetPerspectiveCorners()">üîÑ Reset Corners</button>
                <button class="btn" id="applyPerspectiveBtn" disabled onclick="applyPerspectiveCorrection()">‚úì Apply Correction & Continue</button>
                <button class="btn btn-secondary" onclick="skipPerspectiveCorrection()">Skip (Not Recommended)</button>
            </div>
        </div>

        <!-- Step 3: Processing & Calibration -->
        <div class="card hidden" id="step3">
            <h2>Step 3: AI Processing & Calibration</h2>
            <div class="loading">
                <div class="spinner"></div>
                <div id="processingMessage">Analyzing photo with AI...</div>
            </div>
        </div>

        <!-- Step 4: Review Detected Objects -->
        <div class="card hidden" id="step4">
            <h2>Step 4: Review Detected Objects</h2>
            <div id="perspectiveCorrectionInfo" style="background: #e8f4f8; padding: 10px; border-radius: 6px; margin-bottom: 15px; font-size: 14px;">
                <strong>Perspective Correction:</strong> <span id="perspectiveCorrectionDisplay">Loading...</span>
            </div>
            <div id="detectionModelInfo" style="background: #e8f4f8; padding: 10px; border-radius: 6px; margin-bottom: 15px; font-size: 14px;">
                <strong>Detection Model:</strong> <span id="currentModelDisplay">Loading...</span>
            </div>
            <div id="calibrationInfo" style="background: #e8ffe8; padding: 10px; border-radius: 6px; margin-bottom: 15px; font-size: 14px;">
                <strong>Calibration:</strong> <span id="calibrationMethodDisplay">Loading...</span>
            </div>
            <div class="instructions">
                <strong>AI detected the following objects.</strong> Toggle any incorrect detections off.
            </div>
            <div class="canvas-container">
                <canvas id="detectionCanvas"></canvas>
            </div>
            <div class="objects-list" id="detectedObjectsList"></div>
            <button class="btn" onclick="goToStep(5)">Continue to Placement</button>
            <button class="btn btn-secondary" onclick="retryWithDifferentModel()">üîÑ Retry with Different Model</button>
            <button class="btn btn-secondary" onclick="goToStep(2)">Retake Photo</button>
        </div>

        <!-- Step 5: Place Equipment -->
        <div class="card hidden" id="step5">
            <h2>Step 5: Place Your Equipment</h2>
            <div class="instructions">
                <strong>Drag and drop</strong> the equipment icon to its position in the photo. Clearance zones will update in real-time.
            </div>
            <div id="selectedEquipmentSummary" style="background: #e8f4f8; padding: 10px; border-radius: 6px; margin-bottom: 15px; font-size: 14px;">
                <!-- Will be populated with selected model info -->
            </div>
            <div class="legend">
                <div class="legend-item">
                    <div class="legend-color" style="background: rgba(39, 174, 96, 0.3); border-color: rgba(39, 174, 96, 0.8);"></div>
                    <span>Service Clearance Zone</span>
                </div>
                <div class="legend-item">
                    <div class="legend-color" style="background: rgba(76, 175, 80, 0.7); border-color: #2e7d32;"></div>
                    <span>Equipment (Compliant)</span>
                </div>
                <div class="legend-item">
                    <div class="legend-color" style="background: rgba(244, 67, 54, 0.7); border-color: #c62828;"></div>
                    <span>Equipment (Violation)</span>
                </div>
            </div>
            <div class="canvas-container" id="placementCanvasContainer">
                <canvas id="placementCanvas"></canvas>
            </div>
            <button class="btn btn-success" onclick="confirmPlacement()">Confirm Placement</button>
            <button class="btn btn-secondary" onclick="goToStep(4)">Back to Review</button>
        </div>

        <!-- Step 6: Results -->
        <div class="card hidden" id="step6">
            <h2>Step 6: Clearance Check Results</h2>
            <div class="canvas-container">
                <canvas id="resultCanvas"></canvas>
            </div>
            <div id="resultSummary"></div>
            <button class="btn btn-success" onclick="downloadResult()">Download Annotated Photo</button>
            <button class="btn btn-secondary" onclick="startOver()">Start New Check</button>
        </div>
    </div>

    <script>
        // OpenCV ready flag
        let cvReady = false;

        function onOpenCvReady() {
            cvReady = true;
            console.log('‚úì OpenCV.js loaded and ready for perspective correction');
        }

        // Application State
        const state = {
            equipmentType: null,
            photo: null,
            originalPhoto: null, // Store original before correction
            photoWidth: 0,
            photoHeight: 0,
            scale: {
                pixelsPerMM: 0,
                calibrationComplete: false,
                calibrationLocked: false,  // NEW: Track if calibration is locked from Stage 1
                lockedPixelsPerMM: 0,      // NEW: Store locked calibration value
                calibrationMethod: null,
                calibrationStage: 1        // NEW: Track current calibration stage (1 or 2)
            },
            stage1Photo: null,  // NEW: Store Stage 1 close-up photo
            detectedObjects: [],
            equipmentPosition: null,
            currentStep: 1,
            perspectiveCorrection: {
                enabled: false,
                corners: [], // Array of 4 points {x, y}
                correctedImage: null
            },
            selectedModel: null,  // Store selected model from ModelStore
            modelDimensions: null,  // Store model dimensions separately to avoid mutating EQUIPMENT_CONFIG
            modelName: null  // Store model name separately
        };

        // Equipment Configurations (default values - should not be mutated)
        const EQUIPMENT_CONFIG = {
            flue: {
                name: 'Flue Terminal',
                icon: 'üå¨Ô∏è',
                detectObjects: ['window', 'opening_window', 'air_vent', 'fan_vent', 'door', 'soil_pipe', 'downpipe'],
                clearances: {
                    opening_window: 300,
                    window: 150,
                    air_vent: 300,
                    fan_vent: 300,
                    door: 300,
                    soil_pipe: 300,
                    downpipe: 300
                },
                // Physical dimensions in mm (flue terminal - circular, diameter)
                dimensions: {
                    width: 100,  // diameter
                    height: 100  // diameter
                },
                isInternal: false
            },
            boiler: {
                name: 'Boiler',
                icon: 'üî•',
                detectObjects: ['plug_socket', 'window', 'cupboard', 'shelf', 'wall', 'door'],
                clearances: {
                    plug_socket: 150,
                    window: 100,
                    cupboard: 50,
                    shelf: 300,
                    wall: 50,
                    door: 500
                },
                // Typical wall-hung boiler dimensions in mm
                dimensions: {
                    width: 440,   // width
                    height: 700   // height
                },
                isInternal: true
            },
            radiator: {
                name: 'Radiator',
                icon: '‚ô®Ô∏è',
                detectObjects: ['plug', 'window', 'curtain', 'furniture', 'wall'],
                clearances: {
                    plug: 150,
                    window: 50,
                    curtain: 100,
                    furniture: 150,
                    wall: 50
                },
                // Typical radiator dimensions in mm
                dimensions: {
                    width: 1200,  // width
                    height: 600   // height
                },
                isInternal: true
            },
            cylinder: {
                name: 'Cylinder',
                icon: 'üõ¢Ô∏è',
                detectObjects: ['door', 'shelf', 'pump', 'valve', 'wall', 'ceiling'],
                clearances: {
                    door: 400,
                    shelf: 150,
                    pump: 200,
                    valve: 300,
                    wall: 150,
                    ceiling: 450
                },
                // Typical hot water cylinder dimensions in mm
                dimensions: {
                    width: 450,   // diameter
                    height: 1200  // height
                },
                isInternal: true
            }
        };

        // Step 1: Equipment Selection
        function selectEquipment(type) {
            state.equipmentType = type;

            // Update UI
            document.querySelectorAll('.equipment-card').forEach(card => {
                card.classList.remove('selected');
            });
            document.querySelector(`[data-type="${type}"]`).classList.add('selected');

            document.getElementById('continueToPhoto').disabled = false;
        }

        // Navigation
        function goToStep(stepNumber) {
            // Hide all steps
            for (let i = 1; i <= 6; i++) {
                document.getElementById(`step${i}`)?.classList.add('hidden');
            }
            document.getElementById('step1b')?.classList.add('hidden');
            document.getElementById('step2_5')?.classList.add('hidden');
            document.getElementById('step2a')?.classList.add('hidden');
            document.getElementById('step2b')?.classList.add('hidden');
            document.getElementById('step2c')?.classList.add('hidden');
            document.getElementById('step2d')?.classList.add('hidden');

            // Show target step
            document.getElementById(`step${stepNumber}`).classList.remove('hidden');
            state.currentStep = stepNumber;
        }

        // Navigate to model selection step
        async function goToModelSelection() {
            // Flue doesn't need model selection - it has fixed dimensions
            if (state.equipmentType === 'flue') {
                goToStep(2);
                return;
            }

            // Load models from ModelStore
            try {
                await ModelStore.loadAllModels();
            } catch (error) {
                console.warn('Failed to load models, using default dimensions:', error);
                goToStep(2);
                return;
            }

            // Get models for the selected equipment type
            let models = [];
            if (state.equipmentType === 'boiler') {
                models = ModelStore.getBoilerModels();
            } else if (state.equipmentType === 'radiator') {
                models = ModelStore.getRadiatorModels();
            } else if (state.equipmentType === 'cylinder') {
                models = ModelStore.getCylinderModels();
            }

            if (models.length === 0) {
                console.warn('No models found, using default dimensions');
                goToStep(2);
                return;
            }

            // Show step1b
            for (let i = 1; i <= 6; i++) {
                document.getElementById(`step${i}`)?.classList.add('hidden');
            }
            document.getElementById('step1b').classList.remove('hidden');

            // Populate model selection UI
            populateModelSelection(models);
        }

        // Populate model selection dropdown
        function populateModelSelection(models) {
            const container = document.getElementById('modelSelectionContainer');
            const config = EQUIPMENT_CONFIG[state.equipmentType];

            let html = `
                <div style="margin: 15px 0;">
                    <label for="modelSelect" style="font-weight: 600; display: block; margin-bottom: 8px;">
                        ${config.icon} Select ${config.name} Model:
                    </label>
                    <select id="modelSelect" onchange="onModelSelected()" style="width: 100%; padding: 12px; border-radius: 6px; border: 2px solid #667eea; font-size: 15px;">
                        <option value="">-- Select a model --</option>
            `;

            // Group models by brand for better organization
            const modelsByBrand = {};
            models.forEach(model => {
                const brand = model.brand || 'Other';
                if (!modelsByBrand[brand]) {
                    modelsByBrand[brand] = [];
                }
                modelsByBrand[brand].push(model);
            });

            Object.keys(modelsByBrand).sort().forEach(brand => {
                html += `<optgroup label="${brand}">`;
                modelsByBrand[brand].forEach(model => {
                    const displayName = ModelStore.formatModelName(model, state.equipmentType);
                    const dims = model.dimensions;
                    const dimText = dims ? ` (${dims.width}√ó${dims.height}mm)` : '';
                    html += `<option value="${model.id}">${displayName}${dimText}</option>`;
                });
                html += `</optgroup>`;
            });

            html += `
                    </select>
                </div>
            `;

            container.innerHTML = html;
        }

        // Handle model selection
        function onModelSelected() {
            const select = document.getElementById('modelSelect');
            const modelId = select.value;

            if (!modelId) {
                document.getElementById('selectedModelInfo').style.display = 'none';
                document.getElementById('continueToCalibration').disabled = true;
                state.selectedModel = null;
                return;
            }

            // Get the selected model
            const modelInfo = ModelStore.getModelById(modelId);
            if (!modelInfo) {
                console.error('Model not found:', modelId);
                return;
            }

            state.selectedModel = modelInfo.model;

            // Store model dimensions and name in state (avoid mutating EQUIPMENT_CONFIG)
            if (state.selectedModel.dimensions) {
                state.modelDimensions = {
                    width: state.selectedModel.dimensions.width,
                    height: state.selectedModel.dimensions.height,
                    depth: state.selectedModel.dimensions.depth || 0
                };
                state.modelName = `${state.selectedModel.brand || ''} ${state.selectedModel.range || state.selectedModel.model || ''}`.trim();
            }

            // Show selected model info
            const infoDiv = document.getElementById('selectedModelInfo');
            const detailsDiv = document.getElementById('selectedModelDetails');

            const dims = state.selectedModel.dimensions;
            const clearances = state.selectedModel.serviceClearances;

            let detailsHtml = `
                <div><strong>Brand:</strong> ${state.selectedModel.brand || 'Unknown'}</div>
                <div><strong>Model:</strong> ${state.selectedModel.range || state.selectedModel.model || state.selectedModel.id}</div>
            `;

            if (dims) {
                detailsHtml += `<div><strong>Dimensions:</strong> ${dims.width}mm (W) √ó ${dims.height}mm (H)`;
                if (dims.depth) {
                    detailsHtml += ` √ó ${dims.depth}mm (D)`;
                }
                detailsHtml += `</div>`;
            }

            if (clearances) {
                detailsHtml += `<div style="margin-top: 8px;"><strong>Service Clearances:</strong></div>`;
                if (clearances.front) detailsHtml += `<div>‚Ä¢ Front: ${clearances.front}mm</div>`;
                if (clearances.sides) detailsHtml += `<div>‚Ä¢ Sides: ${clearances.sides}mm</div>`;
                if (clearances.above) detailsHtml += `<div>‚Ä¢ Above: ${clearances.above}mm</div>`;
                if (clearances.below) detailsHtml += `<div>‚Ä¢ Below: ${clearances.below}mm</div>`;
            }

            detailsDiv.innerHTML = detailsHtml;
            infoDiv.style.display = 'block';
            document.getElementById('continueToCalibration').disabled = false;
        }

        // Two-Stage Calibration Navigation Functions
        function goToStage1Calibration() {
            // Hide all steps
            for (let i = 1; i <= 6; i++) {
                document.getElementById(`step${i}`)?.classList.add('hidden');
            }
            document.getElementById('step1b')?.classList.add('hidden');
            document.getElementById('step2a').classList.remove('hidden');
            state.scale.calibrationStage = 1;
        }

        function goToStage2Capture() {
            // Hide all steps
            for (let i = 1; i <= 6; i++) {
                document.getElementById(`step${i}`)?.classList.add('hidden');
            }
            document.getElementById('step1b')?.classList.add('hidden');
            document.getElementById('step2a')?.classList.add('hidden');
            document.getElementById('step2b')?.classList.add('hidden');
            document.getElementById('step2c')?.classList.add('hidden');

            document.getElementById('step2d').classList.remove('hidden');
            state.scale.calibrationStage = 2;

            // Update locked calibration display
            const display = document.getElementById('lockedCalibrationDisplay');
            if (display) {
                display.textContent = `${state.scale.lockedPixelsPerMM.toFixed(3)} pixels/mm from Stage 1 close-up`;
            }
        }

        function retryStage1() {
            // Reset calibration
            state.scale.calibrationLocked = false;
            state.scale.lockedPixelsPerMM = 0;
            state.stage1Photo = null;

            // Go back to Stage 1 photo capture
            goToStage1Calibration();
        }

        // Step 2: Photo Upload Handlers (Old single-stage - kept for compatibility)
        document.getElementById('cameraInput')?.addEventListener('change', handlePhotoUpload);
        document.getElementById('uploadInput')?.addEventListener('change', handlePhotoUpload);

        // NEW: Stage 1 Photo Upload Handlers
        document.getElementById('stage1CameraInput')?.addEventListener('change', handleStage1PhotoUpload);
        document.getElementById('stage1UploadInput')?.addEventListener('change', handleStage1PhotoUpload);

        // NEW: Stage 2 Photo Upload Handlers
        document.getElementById('stage2CameraInput')?.addEventListener('change', handleStage2PhotoUpload);
        document.getElementById('stage2UploadInput')?.addEventListener('change', handleStage2PhotoUpload);

        function handlePhotoUpload(e) {
            const file = e.target.files[0];
            if (!file) return;

            const reader = new FileReader();
            reader.onload = function(event) {
                const img = new Image();
                img.onload = function() {
                    state.photo = img;
                    state.originalPhoto = img; // Store original
                    state.photoWidth = img.width;
                    state.photoHeight = img.height;

                    // Check if OpenCV is loaded
                    if (!cvReady) {
                        console.warn('‚ö†Ô∏è  OpenCV not ready yet, skipping perspective correction');
                        goToStep(3);
                        processPhoto();
                        return;
                    }

                    // Move to perspective correction step
                    goToPerspectiveCorrection();
                };
                img.src = event.target.result;
            };
            reader.readAsDataURL(file);
        }

        // NEW: Handle Stage 1 Photo Upload
        function handleStage1PhotoUpload(e) {
            const file = e.target.files[0];
            if (!file) return;

            const reader = new FileReader();
            reader.onload = function(event) {
                const img = new Image();
                img.onload = function() {
                    state.stage1Photo = img;
                    state.photo = img;
                    state.originalPhoto = img;
                    state.photoWidth = img.width;
                    state.photoHeight = img.height;

                    console.log('üéØ === STAGE 1: CLOSE CALIBRATION ===');
                    console.log('Photo dimensions:', state.photoWidth, 'x', state.photoHeight);

                    // Go to Stage 1 processing
                    document.getElementById('step2a').classList.add('hidden');
                    document.getElementById('step2b').classList.remove('hidden');

                    // Process Stage 1 calibration
                    processStage1Calibration();
                };
                img.src = event.target.result;
            };
            reader.readAsDataURL(file);
        }

        // NEW: Handle Stage 2 Photo Upload
        function handleStage2PhotoUpload(e) {
            const file = e.target.files[0];
            if (!file) return;

            const reader = new FileReader();
            reader.onload = function(event) {
                const img = new Image();
                img.onload = function() {
                    state.photo = img;
                    state.originalPhoto = img;
                    state.photoWidth = img.width;
                    state.photoHeight = img.height;

                    console.log('üì∏ === STAGE 2: WALL CAPTURE ===');
                    console.log('Photo dimensions:', state.photoWidth, 'x', state.photoHeight);
                    console.log('Using locked calibration:', state.scale.lockedPixelsPerMM.toFixed(3), 'pixels/mm');

                    // Use locked calibration from Stage 1
                    state.scale.pixelsPerMM = state.scale.lockedPixelsPerMM;
                    state.scale.calibrationComplete = true;
                    state.scale.calibrationMethod = 'two_stage_blue_card';

                    // Check if OpenCV is loaded for perspective correction
                    if (!cvReady) {
                        console.warn('‚ö†Ô∏è  OpenCV not ready yet, skipping perspective correction');
                        goToStep(3);
                        processPhoto();
                        return;
                    }

                    // Move to perspective correction step
                    goToPerspectiveCorrection();
                };
                img.src = event.target.result;
            };
            reader.readAsDataURL(file);
        }

        // NEW: Process Stage 1 Calibration
        async function processStage1Calibration() {
            try {
                document.getElementById('stage1ProcessingMessage').textContent = 'Detecting blue card for calibration...';

                // Detect blue card
                await detectBlueCard();

                if (state.scale.calibrationComplete && state.scale.pixelsPerMM > 0) {
                    // Lock the calibration
                    state.scale.calibrationLocked = true;
                    state.scale.lockedPixelsPerMM = state.scale.pixelsPerMM;
                    state.scale.calibrationMethod = 'blue_card_stage1';

                    console.log('‚úì Stage 1 calibration locked:', state.scale.lockedPixelsPerMM.toFixed(3), 'pixels/mm');

                    // Show success screen
                    showStage1Success();
                } else {
                    throw new Error('Blue card not detected. Please ensure the card fills 40-60% of the frame.');
                }
            } catch (error) {
                console.error('Stage 1 calibration error:', error);
                alert('‚ö†Ô∏è Stage 1 Calibration Failed\n\n' + error.message + '\n\nPlease try again with:\n‚Ä¢ Blue card filling 40-60% of frame\n‚Ä¢ Good lighting\n‚Ä¢ Card flat against wall');
                retryStage1();
            }
        }

        // NEW: Show Stage 1 Success Screen
        function showStage1Success() {
            // Hide processing screen
            document.getElementById('step2b').classList.add('hidden');

            // Show success screen
            document.getElementById('step2c').classList.remove('hidden');

            // Update calibration info
            const infoDiv = document.getElementById('calibrationLockedInfo');
            infoDiv.innerHTML = `
                <strong>Calibration Scale:</strong> ${state.scale.lockedPixelsPerMM.toFixed(3)} pixels per mm<br>
                <br>
                Based on blue card detection (85mm √ó 54mm standard credit card size)<br>
                <br>
                This calibration is now locked and will be used for Stage 2 measurements.
            `;

            // Draw the Stage 1 photo with blue card highlighted
            const canvas = document.getElementById('stage1Canvas');
            const ctx = canvas.getContext('2d');
            canvas.width = state.photoWidth;
            canvas.height = state.photoHeight;
            ctx.drawImage(state.stage1Photo, 0, 0);

            // Highlight the detected blue card area
            const tempCanvas = document.createElement('canvas');
            const tempCtx = tempCanvas.getContext('2d');
            tempCanvas.width = state.photoWidth;
            tempCanvas.height = state.photoHeight;
            tempCtx.drawImage(state.stage1Photo, 0, 0);

            const imageData = tempCtx.getImageData(0, 0, tempCanvas.width, tempCanvas.height);
            const data = imageData.data;

            // Find blue pixels and draw bounding box
            let bluePixels = [];
            for (let i = 0; i < data.length; i += 4) {
                const r = data[i];
                const g = data[i + 1];
                const b = data[i + 2];

                if (b > r + 30 && b > g + 30 && b > 100) {
                    const x = (i / 4) % tempCanvas.width;
                    const y = Math.floor((i / 4) / tempCanvas.width);
                    bluePixels.push({ x, y });
                }
            }

            if (bluePixels.length > 100) {
                const xs = bluePixels.map(p => p.x);
                const ys = bluePixels.map(p => p.y);
                const minX = Math.min(...xs);
                const maxX = Math.max(...xs);
                const minY = Math.min(...ys);
                const maxY = Math.max(...ys);

                // Draw green box around detected card
                ctx.strokeStyle = '#28a745';
                ctx.lineWidth = 5;
                ctx.strokeRect(minX, minY, maxX - minX, maxY - minY);

                // Draw label
                ctx.fillStyle = 'rgba(40, 167, 69, 0.9)';
                ctx.fillRect(minX, minY - 35, 220, 30);
                ctx.fillStyle = '#fff';
                ctx.font = 'bold 16px Arial';
                ctx.fillText('‚úì Blue Card Detected', minX + 10, minY - 12);
            }
        }

        function goToPerspectiveCorrection() {
            // Show perspective correction step
            for (let i = 1; i <= 6; i++) {
                const stepId = i === 2.5 ? 'step2_5' : `step${i}`;
                document.getElementById(stepId)?.classList.add('hidden');
            }
            document.getElementById('step2_5').classList.remove('hidden');

            // Reset corners
            state.perspectiveCorrection.corners = [];
            updateCornersDisplay();

            // Draw photo on canvas
            const canvas = document.getElementById('perspectiveCanvas');
            const ctx = canvas.getContext('2d');
            canvas.width = state.photoWidth;
            canvas.height = state.photoHeight;
            ctx.drawImage(state.photo, 0, 0);

            // Setup click handler for marking corners
            canvas.onclick = handleCanvasClick;
        }

        function handleCanvasClick(e) {
            const canvas = document.getElementById('perspectiveCanvas');
            const rect = canvas.getBoundingClientRect();
            const scaleX = canvas.width / rect.width;
            const scaleY = canvas.height / rect.height;

            const x = (e.clientX - rect.left) * scaleX;
            const y = (e.clientY - rect.top) * scaleY;

            // Add corner if we have less than 4
            if (state.perspectiveCorrection.corners.length < 4) {
                state.perspectiveCorrection.corners.push({ x, y });
                drawPerspectiveCanvas();
                updateCornersDisplay();

                // Enable apply button when we have 4 corners
                if (state.perspectiveCorrection.corners.length === 4) {
                    document.getElementById('applyPerspectiveBtn').disabled = false;
                }
            }
        }

        function drawPerspectiveCanvas() {
            const canvas = document.getElementById('perspectiveCanvas');
            const ctx = canvas.getContext('2d');

            // Clear and redraw photo
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(state.photo, 0, 0);

            // Draw corners
            const corners = state.perspectiveCorrection.corners;
            corners.forEach((corner, index) => {
                // Draw circle
                ctx.beginPath();
                ctx.arc(corner.x, corner.y, 10, 0, 2 * Math.PI);
                ctx.fillStyle = '#667eea';
                ctx.fill();
                ctx.strokeStyle = '#fff';
                ctx.lineWidth = 3;
                ctx.stroke();

                // Draw number
                ctx.fillStyle = '#fff';
                ctx.font = 'bold 14px Arial';
                ctx.textAlign = 'center';
                ctx.textBaseline = 'middle';
                ctx.fillText((index + 1).toString(), corner.x, corner.y);

                // Draw lines connecting corners
                if (index > 0) {
                    ctx.beginPath();
                    ctx.moveTo(corners[index - 1].x, corners[index - 1].y);
                    ctx.lineTo(corner.x, corner.y);
                    ctx.strokeStyle = '#667eea';
                    ctx.lineWidth = 2;
                    ctx.stroke();
                }

                // Close the quadrilateral if we have 4 corners
                if (corners.length === 4 && index === 3) {
                    ctx.beginPath();
                    ctx.moveTo(corners[3].x, corners[3].y);
                    ctx.lineTo(corners[0].x, corners[0].y);
                    ctx.strokeStyle = '#667eea';
                    ctx.lineWidth = 2;
                    ctx.stroke();
                }
            });
        }

        function updateCornersDisplay() {
            const count = state.perspectiveCorrection.corners.length;
            document.getElementById('cornersCount').textContent = `${count} / 4`;

            const listDiv = document.getElementById('cornersList');
            if (count === 0) {
                listDiv.innerHTML = '<em style="color: #999;">Click 4 corners of a rectangle</em>';
            } else {
                const labels = ['Top-Left', 'Top-Right', 'Bottom-Right', 'Bottom-Left'];
                listDiv.innerHTML = state.perspectiveCorrection.corners
                    .map((c, i) => `‚úì ${labels[i]}: (${Math.round(c.x)}, ${Math.round(c.y)})`)
                    .join('<br>');
            }
        }

        function resetPerspectiveCorners() {
            state.perspectiveCorrection.corners = [];
            drawPerspectiveCanvas();
            updateCornersDisplay();
            document.getElementById('applyPerspectiveBtn').disabled = true;
        }

        function skipPerspectiveCorrection() {
            console.warn('‚ö†Ô∏è  Skipping perspective correction - measurements may be inaccurate!');
            state.perspectiveCorrection.enabled = false;
            goToStep(3);
            processPhoto();
        }

        async function applyPerspectiveCorrection() {
            if (state.perspectiveCorrection.corners.length !== 4) {
                alert('Please mark all 4 corners first!');
                return;
            }

            console.log('üîß === APPLYING PERSPECTIVE CORRECTION ===');
            console.log('Corner points:', state.perspectiveCorrection.corners);

            try {
                // Get source corners (as marked by user)
                const corners = state.perspectiveCorrection.corners;

                // Calculate width and height of destination rectangle
                // Use the maximum distances to preserve detail
                const width1 = Math.sqrt(Math.pow(corners[1].x - corners[0].x, 2) + Math.pow(corners[1].y - corners[0].y, 2));
                const width2 = Math.sqrt(Math.pow(corners[2].x - corners[3].x, 2) + Math.pow(corners[2].y - corners[3].y, 2));
                const height1 = Math.sqrt(Math.pow(corners[3].x - corners[0].x, 2) + Math.pow(corners[3].y - corners[0].y, 2));
                const height2 = Math.sqrt(Math.pow(corners[2].x - corners[1].x, 2) + Math.pow(corners[2].y - corners[1].y, 2));

                const maxWidth = Math.max(width1, width2);
                const maxHeight = Math.max(height1, height2);

                console.log('Destination dimensions:', maxWidth, 'x', maxHeight);

                // Create OpenCV mats
                const src = cv.imread('perspectiveCanvas');

                // Source points (the distorted quadrilateral)
                const srcPoints = cv.matFromArray(4, 1, cv.CV_32FC2, [
                    corners[0].x, corners[0].y,  // Top-left
                    corners[1].x, corners[1].y,  // Top-right
                    corners[2].x, corners[2].y,  // Bottom-right
                    corners[3].x, corners[3].y   // Bottom-left
                ]);

                // Destination points (perfect rectangle)
                const dstPoints = cv.matFromArray(4, 1, cv.CV_32FC2, [
                    0, 0,                    // Top-left
                    maxWidth, 0,             // Top-right
                    maxWidth, maxHeight,     // Bottom-right
                    0, maxHeight             // Bottom-left
                ]);

                // Calculate perspective transform matrix
                const M = cv.getPerspectiveTransform(srcPoints, dstPoints);

                // Create destination mat
                const dst = new cv.Mat();
                const dsize = new cv.Size(maxWidth, maxHeight);

                // Apply warp
                cv.warpPerspective(src, dst, M, dsize, cv.INTER_LINEAR, cv.BORDER_CONSTANT, new cv.Scalar());

                console.log('‚úì Perspective transform applied');

                // Convert corrected image to Image object
                const correctedCanvas = document.createElement('canvas');
                cv.imshow(correctedCanvas, dst);

                const correctedImg = new Image();
                correctedImg.onload = function() {
                    // Update state with corrected image
                    state.photo = correctedImg;
                    state.photoWidth = correctedImg.width;
                    state.photoHeight = correctedImg.height;
                    state.perspectiveCorrection.enabled = true;
                    state.perspectiveCorrection.correctedImage = correctedImg;

                    console.log('‚úì Corrected image dimensions:', state.photoWidth, 'x', state.photoHeight);
                    console.log('=========================================');

                    // Clean up OpenCV mats
                    src.delete();
                    dst.delete();
                    srcPoints.delete();
                    dstPoints.delete();
                    M.delete();

                    // Proceed to AI processing with corrected image
                    goToStep(3);
                    processPhoto();
                };
                correctedImg.src = correctedCanvas.toDataURL();

            } catch (error) {
                console.error('‚ùå Perspective correction failed:', error);
                alert('Perspective correction failed. You can skip this step or try again with different corners.');
            }
        }

        // Step 3: Process Photo with AI
        async function processPhoto() {
            try {
                // Update processing message
                document.getElementById('processingMessage').textContent = 'Detecting objects and calibration card with AI...';

                // Detect objects and credit card using AI Worker (returns both)
                await detectObjects();

                // If AI didn't detect a credit card, try blue card detection as fallback
                if (!state.scale.calibrationComplete) {
                    document.getElementById('processingMessage').textContent = 'AI card detection failed, trying blue card detection...';
                    await detectBlueCard();
                }

                // Move to review step
                goToStep(4);
                drawDetectedObjects();
            } catch (error) {
                console.error('Processing error:', error);
                alert('Error processing photo: ' + error.message);
                goToStep(2);
            }
        }

        // Detect Blue Card for Calibration (Credit Card Size - 85mm x 54mm)
        async function detectBlueCard() {
            return new Promise((resolve) => {
                // Create temporary canvas for blue card detection
                const canvas = document.createElement('canvas');
                const ctx = canvas.getContext('2d');
                canvas.width = state.photoWidth;
                canvas.height = state.photoHeight;
                ctx.drawImage(state.photo, 0, 0);

                const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                const data = imageData.data;

                // Simple blue color detection
                let bluePixels = [];
                for (let i = 0; i < data.length; i += 4) {
                    const r = data[i];
                    const g = data[i + 1];
                    const b = data[i + 2];

                    // Check if pixel is blue (b > r && b > g)
                    if (b > r + 30 && b > g + 30 && b > 100) {
                        const x = (i / 4) % canvas.width;
                        const y = Math.floor((i / 4) / canvas.width);
                        bluePixels.push({ x, y });
                    }
                }

                if (bluePixels.length > 100) {
                    // Calculate bounding box of blue pixels
                    const xs = bluePixels.map(p => p.x);
                    const ys = bluePixels.map(p => p.y);
                    const minX = Math.min(...xs);
                    const maxX = Math.max(...xs);
                    const minY = Math.min(...ys);
                    const maxY = Math.max(...ys);

                    // Credit card dimensions: 85mm x 54mm
                    // Use width (85mm) as the standard measurement
                    const widthPx = maxX - minX;
                    const heightPx = maxY - minY;

                    // Determine which dimension is width (should be larger for credit card)
                    const cardWidthPx = Math.max(widthPx, heightPx);

                    // Calculate pixels per mm based on 85mm credit card width
                    state.scale.pixelsPerMM = cardWidthPx / 85;
                    state.scale.calibrationComplete = true;

                    console.log(`Calibration: ${state.scale.pixelsPerMM.toFixed(2)} pixels per mm (blue card: ${cardWidthPx}px = 85mm)`);
                } else {
                    // Fallback: use default calibration
                    console.warn('Blue card not detected, using default calibration');
                    state.scale.pixelsPerMM = state.photoWidth / 2000; // Assume ~2000mm width
                    state.scale.calibrationComplete = true;
                }

                setTimeout(resolve, 500);
            });
        }

        // Detect Objects using Cloudflare Worker
        async function detectObjects() {
            const config = EQUIPMENT_CONFIG[state.equipmentType];

            // Get selected AI model
            const selectedModel = document.getElementById('aiModelSelect').value;

            // Convert image to base64
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            canvas.width = state.photoWidth;
            canvas.height = state.photoHeight;
            ctx.drawImage(state.photo, 0, 0);
            const imageBase64 = canvas.toDataURL('image/jpeg', 0.8);

            console.log('=== DETECTION ATTEMPT ===');
            console.log('Selected AI Model:', selectedModel);
            console.log('Equipment Type:', state.equipmentType);
            console.log('Image Dimensions:', state.photoWidth, 'x', state.photoHeight);

            try {
                const response = await fetch('https://clearance.martinbibb.workers.dev', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        image: imageBase64,
                        equipmentType: state.equipmentType,
                        detectObjects: config.detectObjects,
                        aiModel: selectedModel
                    })
                });

                if (!response.ok) {
                    throw new Error('API request failed');
                }

                const result = await response.json();

                console.log('Raw API Response:', result);
                console.log('AI Service Used:', result.aiServiceUsed);
                console.log('Model Name:', result.modelName);

                // Update model feedback
                const modelFeedback = document.getElementById('modelFeedback');
                if (modelFeedback) {
                    modelFeedback.textContent = `‚úì Using ${result.modelName || result.aiServiceUsed}`;
                    modelFeedback.style.color = '#2ecc71';
                }

                // Store AI model used
                state.aiModelUsed = result.aiServiceUsed;
                state.modelName = result.modelName;

                // Scale factor: API returns coordinates based on 1000x1000 reference
                const scaleX = state.photoWidth / 1000;
                const scaleY = state.photoHeight / 1000;

                // Process detected objects and scale to actual image dimensions
                state.detectedObjects = (result.objects || []).map(obj => ({
                    ...obj,
                    bounds: {
                        x: obj.bounds.x * scaleX,
                        y: obj.bounds.y * scaleY,
                        width: obj.bounds.width * scaleX,
                        height: obj.bounds.height * scaleY
                    },
                    polygon: obj.polygon ? obj.polygon.map(pt => ({
                        x: pt.x * scaleX,
                        y: pt.y * scaleY
                    })) : undefined
                }));

                console.log(`Objects detected: ${state.detectedObjects.length}`);
                state.detectedObjects.forEach((obj, i) => {
                    console.log(`Object ${i + 1}: ${obj.type}`);
                    console.log(`  Confidence: ${obj.confidence}`);
                    console.log(`  Bounds: x=${obj.bounds.x.toFixed(1)}px, y=${obj.bounds.y.toFixed(1)}px, w=${obj.bounds.width.toFixed(1)}px, h=${obj.bounds.height.toFixed(1)}px`);
                    console.log(`  Polygon points: ${obj.polygon?.length || 0}`);
                });

                // PRIORITY 1: Try flue terminal calibration (most accurate for flue equipment)
                if (result.calibration && result.calibration.flueTerminalDetected) {
                    const flueBounds = result.calibration.flueTerminalBounds.bounds;
                    const flueConfidence = result.calibration.flueTerminalBounds.confidence;
                    const flueDiameter = result.calibration.flueTerminalBounds.diameter || 100;

                    // Scale flue bounds to actual image dimensions
                    const flueWidthPx = flueBounds.width * scaleX;
                    const flueHeightPx = flueBounds.height * scaleY;

                    // For circular flue, use average of width and height
                    const flueActualDiameterPx = (flueWidthPx + flueHeightPx) / 2;

                    // Calculate pixels per mm based on flue diameter (default 100mm)
                    state.scale.pixelsPerMM = flueActualDiameterPx / flueDiameter;
                    state.scale.calibrationComplete = true;
                    state.scale.calibrationMethod = 'flue_terminal';

                    console.log('üéØ === FLUE TERMINAL CALIBRATION (PRIMARY) ===');
                    console.log(`Flue diameter detected: ${flueActualDiameterPx.toFixed(1)}px`);
                    console.log(`Known diameter: ${flueDiameter}mm`);
                    console.log(`Calibration: ${state.scale.pixelsPerMM.toFixed(3)} pixels per mm`);
                    console.log(`Confidence: ${(flueConfidence * 100).toFixed(1)}%`);
                    console.log(`Green box dimensions: ${flueWidthPx.toFixed(1)}px √ó ${flueHeightPx.toFixed(1)}px`);
                    console.log('===========================================');
                }
                // PRIORITY 2: Try credit card calibration (fallback)
                else if (result.calibration && result.calibration.creditCardDetected) {
                    const cardBounds = result.calibration.creditCardBounds.bounds;
                    const cardConfidence = result.calibration.creditCardBounds.confidence;

                    // Scale card bounds to actual image dimensions
                    const cardWidthPx = cardBounds.width * scaleX;
                    const cardHeightPx = cardBounds.height * scaleY;

                    // Determine which dimension is width (should be larger for credit card)
                    const actualCardWidthPx = Math.max(cardWidthPx, cardHeightPx);

                    // Calculate pixels per mm based on 85mm credit card width
                    state.scale.pixelsPerMM = actualCardWidthPx / 85;
                    state.scale.calibrationComplete = true;
                    state.scale.calibrationMethod = 'credit_card';

                    console.log('üí≥ === CREDIT CARD CALIBRATION (FALLBACK) ===');
                    console.log(`Card width detected: ${actualCardWidthPx.toFixed(1)}px`);
                    console.log(`Known width: 85mm`);
                    console.log(`Calibration: ${state.scale.pixelsPerMM.toFixed(3)} pixels per mm`);
                    console.log(`Confidence: ${(cardConfidence * 100).toFixed(1)}%`);
                    console.log('============================================');
                } else {
                    console.log('‚ö†Ô∏è  No flue or credit card detected by AI, will try blue card fallback');
                }

                console.log('========================');

            } catch (error) {
                console.error('AI Detection Error:', error);

                // Fallback: Use mock data for demonstration
                state.detectedObjects = generateMockDetections();
            }
        }

        // Generate Mock Detections (fallback)
        function generateMockDetections() {
            const config = EQUIPMENT_CONFIG[state.equipmentType];
            const mockObjects = [];

            // Generate random mock detections based on equipment type
            const objectTypes = config.detectObjects;
            const numObjects = Math.floor(Math.random() * 3) + 2; // 2-4 objects

            for (let i = 0; i < numObjects && i < objectTypes.length; i++) {
                const type = objectTypes[i];
                mockObjects.push({
                    type: type,
                    label: type.replace(/_/g, ' ').toUpperCase(),
                    bounds: {
                        x: Math.random() * (state.photoWidth * 0.6) + (state.photoWidth * 0.1),
                        y: Math.random() * (state.photoHeight * 0.6) + (state.photoHeight * 0.1),
                        width: Math.random() * 200 + 100,
                        height: Math.random() * 200 + 100
                    },
                    confidence: Math.random() * 0.3 + 0.7,
                    enabled: true
                });
            }

            return mockObjects;
        }

        // Retry with Different Model
        function retryWithDifferentModel() {
            if (!state.photo) {
                alert('No photo loaded. Please upload a photo first.');
                return;
            }

            // Go back to step 2 to select a different model
            goToStep(2);

            // Show message
            const modelFeedback = document.getElementById('modelFeedback');
            if (modelFeedback) {
                modelFeedback.textContent = '‚ö° Select a different model and the photo will be re-analyzed';
                modelFeedback.style.color = '#667eea';
            }
        }

        // Step 4: Draw Detected Objects
        function drawDetectedObjects() {
            const canvas = document.getElementById('detectionCanvas');
            const ctx = canvas.getContext('2d');

            canvas.width = state.photoWidth;
            canvas.height = state.photoHeight;

            // Update perspective correction display
            const perspectiveDisplay = document.getElementById('perspectiveCorrectionDisplay');
            if (perspectiveDisplay) {
                if (state.perspectiveCorrection.enabled) {
                    perspectiveDisplay.innerHTML = `‚úÖ <strong>Applied</strong> - Image corrected for camera angle`;
                    perspectiveDisplay.parentElement.style.background = '#d4edda';
                } else {
                    perspectiveDisplay.innerHTML = `‚ö†Ô∏è <strong>Not Applied</strong> - Measurements may be less accurate`;
                    perspectiveDisplay.parentElement.style.background = '#fff3cd';
                }
            }

            // Update model display
            const modelDisplay = document.getElementById('currentModelDisplay');
            if (modelDisplay) {
                modelDisplay.textContent = `${state.modelName || state.aiModelUsed || 'Unknown'} (${state.detectedObjects.length} objects detected)`;
            }

            // Update calibration display
            const calibrationDisplay = document.getElementById('calibrationMethodDisplay');
            if (calibrationDisplay && state.scale.calibrationComplete) {
                const method = state.scale.calibrationMethod || 'unknown';
                const ppmm = state.scale.pixelsPerMM.toFixed(3);
                if (method === 'two_stage_blue_card') {
                    calibrationDisplay.innerHTML = `üéØ <strong>Two-Stage Blue Card (85mm)</strong> - ${ppmm} px/mm - Locked from Stage 1 close-up`;
                    calibrationDisplay.parentElement.style.background = '#d4edda';
                } else if (method === 'blue_card_stage1') {
                    calibrationDisplay.innerHTML = `üéØ <strong>Blue Card Stage 1 (85mm)</strong> - ${ppmm} px/mm`;
                    calibrationDisplay.parentElement.style.background = '#d4edda';
                } else if (method === 'flue_terminal') {
                    calibrationDisplay.innerHTML = `üéØ <strong>Flue Terminal (100mm)</strong> - ${ppmm} px/mm`;
                    calibrationDisplay.parentElement.style.background = '#d4edda';
                } else if (method === 'credit_card') {
                    calibrationDisplay.innerHTML = `üí≥ <strong>Credit Card (85mm)</strong> - ${ppmm} px/mm`;
                    calibrationDisplay.parentElement.style.background = '#fff3cd';
                } else {
                    calibrationDisplay.innerHTML = `üìè <strong>Default</strong> - ${ppmm} px/mm`;
                    calibrationDisplay.parentElement.style.background = '#f8d7da';
                }
            }

            // Draw photo
            ctx.drawImage(state.photo, 0, 0);

            // Draw detected objects
            state.detectedObjects.forEach((obj, index) => {
                if (!obj.enabled) return;

                ctx.strokeStyle = '#00ff00';
                ctx.lineWidth = 3;
                ctx.strokeRect(obj.bounds.x, obj.bounds.y, obj.bounds.width, obj.bounds.height);

                // Label
                ctx.fillStyle = 'rgba(0, 255, 0, 0.8)';
                ctx.fillRect(obj.bounds.x, obj.bounds.y - 25, 150, 25);
                ctx.fillStyle = '#000';
                ctx.font = 'bold 14px Arial';
                ctx.fillText(`${obj.label} (${Math.round(obj.confidence * 100)}%)`, obj.bounds.x + 5, obj.bounds.y - 7);
            });

            // Update objects list
            updateObjectsList();
        }

        function updateObjectsList() {
            const list = document.getElementById('detectedObjectsList');
            const config = EQUIPMENT_CONFIG[state.equipmentType];

            list.innerHTML = '<h3 style="margin-bottom: 15px;">Detected Objects:</h3>';

            state.detectedObjects.forEach((obj, index) => {
                const clearance = config.clearances[obj.type] || 100;
                const item = document.createElement('div');
                item.className = 'object-item';
                item.innerHTML = `
                    <div class="info">
                        <div class="name">${obj.label}</div>
                        <div class="clearance">Required clearance: ${clearance}mm</div>
                    </div>
                    <label class="toggle">
                        <input type="checkbox" ${obj.enabled ? 'checked' : ''}
                               onchange="toggleObject(${index})">
                        <span style="margin-left: 8px;">Include</span>
                    </label>
                `;
                list.appendChild(item);
            });
        }

        function toggleObject(index) {
            state.detectedObjects[index].enabled = !state.detectedObjects[index].enabled;
            drawDetectedObjects();
        }

        // Step 5: Place Equipment
        function goToStep5() {
            goToStep(5);

            // Show calibration warning if using flue equipment without flue calibration
            if (state.equipmentType === 'flue' && state.scale.calibrationMethod !== 'flue_terminal') {
                console.warn('‚ö†Ô∏è  CALIBRATION WARNING: Using flue equipment but calibration was not done with flue terminal.');
                console.warn('    For most accurate results, ensure the flue terminal is visible and detected by the AI.');
                console.warn(`    Current calibration method: ${state.scale.calibrationMethod}`);

                alert('‚ö†Ô∏è Calibration Notice:\n\nYou are checking flue clearances but the calibration was not done using the flue terminal itself.\n\nFor most accurate results:\n1. Ensure the flue terminal is visible in the photo\n2. Use a model that can detect the flue (try different models)\n3. The flue terminal (100mm diameter) provides the most reliable calibration\n\nCurrent calibration: ' + (state.scale.calibrationMethod || 'unknown'));
            }

            setupPlacementCanvas();
        }

        function setupPlacementCanvas() {
            const canvas = document.getElementById('placementCanvas');
            const ctx = canvas.getContext('2d');
            const config = EQUIPMENT_CONFIG[state.equipmentType];

            canvas.width = state.photoWidth;
            canvas.height = state.photoHeight;

            // Set initial equipment position (center)
            if (!state.equipmentPosition) {
                state.equipmentPosition = {
                    x: state.photoWidth / 2,
                    y: state.photoHeight / 2
                };
            }

            // Update equipment summary display
            const summaryDiv = document.getElementById('selectedEquipmentSummary');
            if (summaryDiv) {
                // Use state.modelName and state.modelDimensions if available
                const displayName = state.modelName || config.name;
                const dims = state.modelDimensions || config.dimensions;
                let summaryHtml = `<strong>${config.icon} ${displayName}</strong>`;
                summaryHtml += ` (${dims.width}mm √ó ${dims.height}mm)`;
                
                if (state.selectedModel && state.selectedModel.serviceClearances) {
                    const sc = state.selectedModel.serviceClearances;
                    summaryHtml += `<br><small>Service Clearances: Front ${sc.front}mm, Sides ${sc.sides}mm, Above ${sc.above}mm, Below ${sc.below}mm</small>`;
                }
                summaryDiv.innerHTML = summaryHtml;
            }

            drawPlacementScene();
            setupDragging(canvas);
        }

        function drawPlacementScene() {
            const canvas = document.getElementById('placementCanvas');
            const ctx = canvas.getContext('2d');
            const config = EQUIPMENT_CONFIG[state.equipmentType];
            
            // Use model dimensions from state if available, otherwise fall back to config defaults
            const dimensions = state.modelDimensions || config.dimensions;
            const displayName = state.modelName || config.name;

            ctx.clearRect(0, 0, canvas.width, canvas.height);

            // Draw photo
            ctx.drawImage(state.photo, 0, 0);

            // Log calibration info
            console.log('=== PLACEMENT & CLEARANCE CALCULATION ===');
            console.log('Calibration method:', state.scale.calibrationMethod);
            console.log('Pixels per mm:', state.scale.pixelsPerMM.toFixed(3));
            if (state.selectedModel) {
                console.log('Selected model:', state.selectedModel.brand, state.selectedModel.range || state.selectedModel.model);
            }

            // Calculate equipment dimensions in pixels
            const equipWidthPx = dimensions.width * state.scale.pixelsPerMM;
            const equipHeightPx = dimensions.height * state.scale.pixelsPerMM;

            console.log('Equipment dimensions:');
            console.log(`  Physical: ${dimensions.width}mm √ó ${dimensions.height}mm`);
            console.log(`  On screen: ${equipWidthPx.toFixed(1)}px √ó ${equipHeightPx.toFixed(1)}px`);

            // Equipment rectangle (centered on position)
            const equipRect = {
                x: state.equipmentPosition.x - equipWidthPx / 2,
                y: state.equipmentPosition.y - equipHeightPx / 2,
                width: equipWidthPx,
                height: equipHeightPx
            };

            // Get service clearances from selected model or use defaults
            let serviceClearances = { front: 0, sides: 0, above: 0, below: 0 };
            if (state.selectedModel && state.selectedModel.serviceClearances) {
                serviceClearances = state.selectedModel.serviceClearances;
                console.log('Using model service clearances:', serviceClearances);
            } else {
                // Use maximum from obstacle clearances as fallback
                const maxClearanceMM = Math.max(...Object.values(config.clearances));
                serviceClearances = { front: maxClearanceMM, sides: maxClearanceMM, above: maxClearanceMM, below: maxClearanceMM };
            }

            // Draw asymmetric service clearance zones if model has specific clearances
            const frontClearancePx = (serviceClearances.front || 0) * state.scale.pixelsPerMM;
            const sideClearancePx = (serviceClearances.sides || 0) * state.scale.pixelsPerMM;
            const aboveClearancePx = (serviceClearances.above || 0) * state.scale.pixelsPerMM;
            const belowClearancePx = (serviceClearances.below || 0) * state.scale.pixelsPerMM;

            // Draw equipment clearance zone (service access area) - asymmetric
            ctx.fillStyle = 'rgba(39, 174, 96, 0.2)';  // Green for service area
            ctx.fillRect(
                equipRect.x - sideClearancePx,
                equipRect.y - aboveClearancePx,
                equipRect.width + (2 * sideClearancePx),
                equipRect.height + aboveClearancePx + belowClearancePx
            );

            // Draw clearance zone border
            ctx.strokeStyle = 'rgba(39, 174, 96, 0.8)';
            ctx.setLineDash([5, 5]);
            ctx.lineWidth = 2;
            ctx.strokeRect(
                equipRect.x - sideClearancePx,
                equipRect.y - aboveClearancePx,
                equipRect.width + (2 * sideClearancePx),
                equipRect.height + aboveClearancePx + belowClearancePx
            );
            ctx.setLineDash([]);

            // Draw label for service clearance
            // Check if any specific clearances exist to show detailed label
            const hasSpecificClearances = serviceClearances.sides || serviceClearances.above || serviceClearances.below || serviceClearances.front;
            const clearanceLabel = hasSpecificClearances ? 
                `Service: ${serviceClearances.sides || 0}mm sides, ${serviceClearances.above || 0}mm above, ${serviceClearances.below || 0}mm below` :
                `Service Zone: ${Object.values(serviceClearances)[0] || 0}mm`;
            
            ctx.fillStyle = 'rgba(39, 174, 96, 0.9)';
            ctx.fillRect(equipRect.x - sideClearancePx, equipRect.y - aboveClearancePx - 30, Math.max(300, equipRect.width + (2 * sideClearancePx)), 25);
            ctx.fillStyle = '#fff';
            ctx.font = 'bold 12px Arial';
            ctx.textAlign = 'left';
            ctx.textBaseline = 'top';
            ctx.fillText(clearanceLabel, equipRect.x - sideClearancePx + 5, equipRect.y - aboveClearancePx - 25);

            // Check for violations with detected objects
            const violations = [];
            console.log(`Checking clearances for ${state.detectedObjects.filter(o => o.enabled).length} enabled objects:`);

            state.detectedObjects.forEach((obj, index) => {
                if (!obj.enabled) return;

                const clearanceMM = config.clearances[obj.type] || 100;
                const clearancePx = clearanceMM * state.scale.pixelsPerMM;

                console.log(`Object ${index + 1}: ${obj.type}`);
                console.log(`  Required clearance: ${clearanceMM}mm = ${clearancePx.toFixed(1)}px`);
                console.log(`  Object bounds: x=${obj.bounds.x.toFixed(1)}px, y=${obj.bounds.y.toFixed(1)}px, w=${obj.bounds.width.toFixed(1)}px, h=${obj.bounds.height.toFixed(1)}px`);

                // Check if detected object intrudes into equipment's clearance zone
                const clearanceZone = {
                    x: equipRect.x - clearancePx,
                    y: equipRect.y - clearancePx,
                    width: equipRect.width + (2 * clearancePx),
                    height: equipRect.height + (2 * clearancePx)
                };

                const isOverlapping = checkRectOverlap(clearanceZone, obj.bounds);

                console.log(`  Clearance zone: x=${clearanceZone.x.toFixed(1)}px, y=${clearanceZone.y.toFixed(1)}px, w=${clearanceZone.width.toFixed(1)}px, h=${clearanceZone.height.toFixed(1)}px`);
                console.log(`  Overlapping: ${isOverlapping ? '‚ùå VIOLATION' : '‚úì OK'}`);

                // Draw detected object with clearance zone
                if (isOverlapping) {
                    // Draw violation zone around the object
                    ctx.fillStyle = 'rgba(244, 67, 54, 0.3)';  // Red for violation
                    ctx.fillRect(
                        obj.bounds.x - clearancePx,
                        obj.bounds.y - clearancePx,
                        obj.bounds.width + (2 * clearancePx),
                        obj.bounds.height + (2 * clearancePx)
                    );
                    violations.push(obj);
                }

                // Draw object box
                ctx.strokeStyle = isOverlapping ? '#f44336' : '#666';
                ctx.lineWidth = 3;
                ctx.strokeRect(obj.bounds.x, obj.bounds.y, obj.bounds.width, obj.bounds.height);

                // Draw object label
                ctx.fillStyle = isOverlapping ? 'rgba(244, 67, 54, 0.9)' : 'rgba(96, 125, 139, 0.9)';
                const labelWidth = Math.min(200, obj.bounds.width);
                ctx.fillRect(obj.bounds.x, obj.bounds.y - 25, labelWidth, 25);
                ctx.fillStyle = '#fff';
                ctx.font = 'bold 12px Arial';
                ctx.textAlign = 'left';
                ctx.fillText(
                    `${obj.label} (${clearanceMM}mm req)`,
                    obj.bounds.x + 5,
                    obj.bounds.y - 10
                );
            });

            // Draw the equipment itself with actual dimensions
            ctx.fillStyle = violations.length > 0 ?
                'rgba(244, 67, 54, 0.7)' :  // Red if violations
                'rgba(76, 175, 80, 0.7)';   // Green if compliant
            ctx.fillRect(equipRect.x, equipRect.y, equipRect.width, equipRect.height);

            // Draw equipment border
            ctx.strokeStyle = violations.length > 0 ? '#c62828' : '#2e7d32';
            ctx.lineWidth = 4;
            ctx.strokeRect(equipRect.x, equipRect.y, equipRect.width, equipRect.height);

            // Draw equipment icon in center
            ctx.font = 'bold 48px Arial';
            ctx.fillStyle = '#fff';
            ctx.textAlign = 'center';
            ctx.textBaseline = 'middle';
            ctx.fillText(config.icon, state.equipmentPosition.x, state.equipmentPosition.y);

            // Draw equipment label
            ctx.fillStyle = violations.length > 0 ?
                'rgba(244, 67, 54, 0.9)' :
                'rgba(76, 175, 80, 0.9)';
            ctx.fillRect(equipRect.x, equipRect.y + equipRect.height, equipRect.width, 30);
            ctx.fillStyle = '#fff';
            ctx.font = 'bold 14px Arial';
            ctx.textAlign = 'center';
            ctx.textBaseline = 'top';
            ctx.fillText(
                `${displayName} (${dimensions.width}√ó${dimensions.height}mm)`,
                state.equipmentPosition.x,
                equipRect.y + equipRect.height + 8
            );

            // Store violations for later
            state.violations = violations;

            console.log(`\nSummary:`);
            console.log(`  Total violations: ${violations.length}`);
            console.log(`  Status: ${violations.length > 0 ? '‚ùå NON-COMPLIANT' : '‚úì COMPLIANT'}`);
            console.log('=========================================');
        }

        function checkOverlap(point, rect) {
            return point.x >= rect.x &&
                   point.x <= rect.x + rect.width &&
                   point.y >= rect.y &&
                   point.y <= rect.y + rect.height;
        }

        function checkRectOverlap(rect1, rect2) {
            // Check if two rectangles overlap
            return !(rect1.x + rect1.width < rect2.x ||
                     rect2.x + rect2.width < rect1.x ||
                     rect1.y + rect1.height < rect2.y ||
                     rect2.y + rect2.height < rect1.y);
        }

        function setupDragging(canvas) {
            let isDragging = false;

            const getCoords = (e) => {
                const rect = canvas.getBoundingClientRect();
                const scaleX = canvas.width / rect.width;
                const scaleY = canvas.height / rect.height;
                const clientX = e.touches ? e.touches[0].clientX : e.clientX;
                const clientY = e.touches ? e.touches[0].clientY : e.clientY;
                return {
                    x: (clientX - rect.left) * scaleX,
                    y: (clientY - rect.top) * scaleY
                };
            };

            const isOverEquipment = (coords) => {
                const config = EQUIPMENT_CONFIG[state.equipmentType];
                const equipWidthPx = config.dimensions.width * state.scale.pixelsPerMM;
                const equipHeightPx = config.dimensions.height * state.scale.pixelsPerMM;

                const equipRect = {
                    x: state.equipmentPosition.x - equipWidthPx / 2,
                    y: state.equipmentPosition.y - equipHeightPx / 2,
                    width: equipWidthPx,
                    height: equipHeightPx
                };

                return coords.x >= equipRect.x &&
                       coords.x <= equipRect.x + equipRect.width &&
                       coords.y >= equipRect.y &&
                       coords.y <= equipRect.y + equipRect.height;
            };

            canvas.addEventListener('mousedown', (e) => {
                const coords = getCoords(e);
                if (isOverEquipment(coords)) {
                    isDragging = true;
                }
            });

            canvas.addEventListener('touchstart', (e) => {
                e.preventDefault();
                const coords = getCoords(e);
                if (isOverEquipment(coords)) {
                    isDragging = true;
                }
            });

            canvas.addEventListener('mousemove', (e) => {
                if (!isDragging) return;
                state.equipmentPosition = getCoords(e);
                drawPlacementScene();
            });

            canvas.addEventListener('touchmove', (e) => {
                e.preventDefault();
                if (!isDragging) return;
                state.equipmentPosition = getCoords(e);
                drawPlacementScene();
            });

            canvas.addEventListener('mouseup', () => isDragging = false);
            canvas.addEventListener('touchend', () => isDragging = false);
            canvas.addEventListener('mouseleave', () => isDragging = false);
        }

        // Step 6: Confirm Placement
        function confirmPlacement() {
            goToStep(6);
            drawFinalResult();
        }

        function drawFinalResult() {
            const canvas = document.getElementById('resultCanvas');
            const ctx = canvas.getContext('2d');
            const config = EQUIPMENT_CONFIG[state.equipmentType];

            canvas.width = state.photoWidth;
            canvas.height = state.photoHeight;

            // Draw the placement scene
            ctx.drawImage(document.getElementById('placementCanvas'), 0, 0);

            // Generate result summary
            const resultDiv = document.getElementById('resultSummary');
            const isCompliant = state.violations.length === 0;

            if (isCompliant) {
                resultDiv.innerHTML = `
                    <div class="result compliant">
                        <div class="icon">‚úÖ</div>
                        <div>CLEARANCE COMPLIANT</div>
                        <div style="font-size: 16px; margin-top: 10px; opacity: 0.9;">
                            ${config.name} position meets all clearance requirements
                        </div>
                    </div>
                `;
            } else {
                const violationsList = state.violations.map(v =>
                    `<li>Too close to ${v.label} (requires ${config.clearances[v.type]}mm clearance)</li>`
                ).join('');

                resultDiv.innerHTML = `
                    <div class="result non-compliant">
                        <div class="icon">‚ö†Ô∏è</div>
                        <div>CLEARANCE VIOLATION</div>
                        <div class="violations">
                            <strong>Issues found:</strong>
                            <ul>${violationsList}</ul>
                        </div>
                    </div>
                `;
            }
        }

        function downloadResult() {
            const canvas = document.getElementById('resultCanvas');
            const link = document.createElement('a');
            link.download = `clearance-check-${state.equipmentType}-${Date.now()}.png`;
            link.href = canvas.toDataURL();
            link.click();
        }

        function startOver() {
            location.reload();
        }

        // Initialize
        console.log('Clearance Genie AI initialized');
    </script>
</body>
</html>
